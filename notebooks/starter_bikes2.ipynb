{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_bikes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitziVite/machine_learning/blob/main/notebooks/starter_bikes2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "09c3ab1e-b2a2-4c4b-bb7b-0ec9c5143dcb"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "bikes.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     dteday   hr  casual  registered  temp_c  feels_like_c     hum  windspeed  \\\n",
              "0  1/1/2011  0.0       3          13     3.0           3.0  0.7957        0.8   \n",
              "1  1/1/2011  1.0       8          30     1.7           1.7  0.8272        0.8   \n",
              "2  1/1/2011  2.0       5          26     1.9           1.9  0.8157        1.1   \n",
              "3  1/1/2011  3.0       3           9     2.5           2.5  0.7831        0.8   \n",
              "4  1/1/2011  4.0       0           1     2.0           2.0  0.8075        1.1   \n",
              "\n",
              "   weathersit  season  holiday  workingday  \n",
              "0           1       1        0           0  \n",
              "1           1       1        0           0  \n",
              "2           1       1        0           0  \n",
              "3           1       1        0           0  \n",
              "4           1       1        0           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2438af7e-2281-47b4-bd1d-f36937d5e475\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>hr</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>temp_c</th>\n",
              "      <th>feels_like_c</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>workingday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.7957</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>1.7</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.8272</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>26</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.8157</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.7831</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1/1/2011</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8075</td>\n",
              "      <td>1.1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2438af7e-2281-47b4-bd1d-f36937d5e475')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2438af7e-2281-47b4-bd1d-f36937d5e475 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2438af7e-2281-47b4-bd1d-f36937d5e475');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03ade993-0e22-416b-b3a9-ed34bf8eba80\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03ade993-0e22-416b-b3a9-ed34bf8eba80')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03ade993-0e22-416b-b3a9-ed34bf8eba80 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "bikes"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "bikes[\"total_rentals\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "bikes[\"dteday\"] = pd.to_datetime(bikes[\"dteday\"])\n",
        "bikes[\"day\"] = bikes[\"dteday\"].dt.day\n",
        "bikes[\"month\"] = bikes[\"dteday\"].dt.month\n",
        "bikes[\"year\"] = bikes[\"dteday\"].dt.year\n",
        "\n",
        "features = [\n",
        "    \"hr\", \"temp_c\", \"feels_like_c\", \"hum\", \"windspeed\",\n",
        "    \"weathersit\", \"season\", \"holiday\", \"workingday\",\n",
        "    \"day\", \"month\", \"year\"\n",
        "]\n",
        "\n",
        "X = bikes[features]\n",
        "y = bikes[\"total_rentals\"]\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30597b0-56a9-41ee-89c8-c1076cf67298"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)), # Use Input layer for specifying input shape\n",
        "    Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0005)), # Adjusted L2 strength\n",
        "    Dropout(0.3), # Added Dropout layer\n",
        "    Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0005)), # Adjusted L2 strength\n",
        "    Dropout(0.3), # Added Dropout layer\n",
        "    Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.0005)), # Adjusted L2 strength\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=250,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {mae:.2f}\")\n",
        "\n",
        "# Predictions\n",
        "bikes[\"predicted_total\"] = model.predict(scaler.transform(X))\n",
        "\n",
        "# Save only the first 384 predictions as 'total_rentals'\n",
        "bikes[\"predicted_total\"].head(384).to_csv(\"bike_predictions.csv\", index=False, header=['total_rentals'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 110124.8047 - mae: 227.9531 - val_loss: 70658.0547 - val_mae: 193.2129\n",
            "Epoch 2/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 72655.0781 - mae: 194.0932 - val_loss: 68809.3516 - val_mae: 188.6392\n",
            "Epoch 3/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 69637.1562 - mae: 187.4944 - val_loss: 56830.0117 - val_mae: 160.7608\n",
            "Epoch 4/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 59911.3867 - mae: 169.6272 - val_loss: 48358.9258 - val_mae: 146.2763\n",
            "Epoch 5/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 53917.1562 - mae: 154.6009 - val_loss: 45600.4883 - val_mae: 133.9125\n",
            "Epoch 6/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 49602.5859 - mae: 146.5345 - val_loss: 42410.7695 - val_mae: 135.0581\n",
            "Epoch 7/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 48698.7148 - mae: 145.2081 - val_loss: 41163.1172 - val_mae: 129.4498\n",
            "Epoch 8/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 47371.9492 - mae: 142.6853 - val_loss: 39173.5703 - val_mae: 130.7490\n",
            "Epoch 9/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 46248.2852 - mae: 140.5211 - val_loss: 37412.0508 - val_mae: 126.1881\n",
            "Epoch 10/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 43426.2617 - mae: 136.5567 - val_loss: 35837.4961 - val_mae: 117.3092\n",
            "Epoch 11/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 40311.3945 - mae: 130.9539 - val_loss: 30960.9023 - val_mae: 113.0331\n",
            "Epoch 12/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 37872.5117 - mae: 127.5675 - val_loss: 28768.6523 - val_mae: 107.7827\n",
            "Epoch 13/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 35854.8477 - mae: 124.2297 - val_loss: 26365.9160 - val_mae: 105.4027\n",
            "Epoch 14/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 33399.1133 - mae: 119.5346 - val_loss: 25373.3945 - val_mae: 101.0032\n",
            "Epoch 15/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 32647.1680 - mae: 117.1886 - val_loss: 23396.0449 - val_mae: 99.3081\n",
            "Epoch 16/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 31147.8848 - mae: 115.0520 - val_loss: 24152.9980 - val_mae: 97.2996\n",
            "Epoch 17/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 31030.5254 - mae: 114.3971 - val_loss: 23562.0352 - val_mae: 97.6236\n",
            "Epoch 18/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 29740.3340 - mae: 112.3228 - val_loss: 22266.0469 - val_mae: 95.1408\n",
            "Epoch 19/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 30177.1094 - mae: 112.9342 - val_loss: 21739.2656 - val_mae: 96.5002\n",
            "Epoch 20/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 29820.5352 - mae: 111.8153 - val_loss: 22304.7168 - val_mae: 95.1023\n",
            "Epoch 21/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 29473.6719 - mae: 112.1386 - val_loss: 21941.8125 - val_mae: 94.0973\n",
            "Epoch 22/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 28845.3652 - mae: 110.1076 - val_loss: 21419.2227 - val_mae: 93.0233\n",
            "Epoch 23/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 28912.2031 - mae: 110.4350 - val_loss: 23100.7695 - val_mae: 95.6250\n",
            "Epoch 24/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 28341.7324 - mae: 109.2868 - val_loss: 20840.6152 - val_mae: 92.5415\n",
            "Epoch 25/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 27901.3418 - mae: 108.7851 - val_loss: 21875.3242 - val_mae: 91.7182\n",
            "Epoch 26/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 27306.9531 - mae: 107.6936 - val_loss: 18870.5098 - val_mae: 86.9506\n",
            "Epoch 27/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 27029.4004 - mae: 106.7877 - val_loss: 19245.3965 - val_mae: 89.2058\n",
            "Epoch 28/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 26607.2344 - mae: 105.6843 - val_loss: 19859.5430 - val_mae: 88.1203\n",
            "Epoch 29/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 26155.8418 - mae: 104.6894 - val_loss: 18384.7871 - val_mae: 85.6132\n",
            "Epoch 30/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 25261.1094 - mae: 103.3204 - val_loss: 18257.2266 - val_mae: 86.0793\n",
            "Epoch 31/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 24762.4102 - mae: 102.9055 - val_loss: 18410.1250 - val_mae: 86.4278\n",
            "Epoch 32/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 24365.6152 - mae: 102.2267 - val_loss: 17216.1230 - val_mae: 83.6390\n",
            "Epoch 33/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 24482.6895 - mae: 101.2501 - val_loss: 16781.4863 - val_mae: 82.3225\n",
            "Epoch 34/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 23546.8906 - mae: 100.0515 - val_loss: 16157.9180 - val_mae: 82.1027\n",
            "Epoch 35/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 23616.7480 - mae: 99.9714 - val_loss: 16871.4941 - val_mae: 82.3490\n",
            "Epoch 36/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 23671.7305 - mae: 100.0176 - val_loss: 17172.8398 - val_mae: 83.3089\n",
            "Epoch 37/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 23046.7832 - mae: 98.9065 - val_loss: 16297.7920 - val_mae: 81.3191\n",
            "Epoch 38/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 23457.3027 - mae: 99.1888 - val_loss: 16694.5723 - val_mae: 81.9945\n",
            "Epoch 39/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 22644.6973 - mae: 98.0418 - val_loss: 16668.6602 - val_mae: 82.3138\n",
            "Epoch 40/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 22766.5156 - mae: 97.3877 - val_loss: 15080.1816 - val_mae: 79.4455\n",
            "Epoch 41/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 22425.5176 - mae: 97.3483 - val_loss: 15502.8154 - val_mae: 79.2797\n",
            "Epoch 42/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 22186.7676 - mae: 96.9440 - val_loss: 14904.3037 - val_mae: 77.7218\n",
            "Epoch 43/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 22056.7051 - mae: 96.4513 - val_loss: 15841.1826 - val_mae: 79.7202\n",
            "Epoch 44/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 22366.7383 - mae: 97.2094 - val_loss: 14982.8037 - val_mae: 77.7941\n",
            "Epoch 45/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 21641.5195 - mae: 95.3721 - val_loss: 15371.8838 - val_mae: 79.0536\n",
            "Epoch 46/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21679.4297 - mae: 95.5987 - val_loss: 14747.3301 - val_mae: 77.4641\n",
            "Epoch 47/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21718.1738 - mae: 95.3631 - val_loss: 15155.5615 - val_mae: 78.4563\n",
            "Epoch 48/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21273.2969 - mae: 95.1360 - val_loss: 14544.8457 - val_mae: 77.6292\n",
            "Epoch 49/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 21165.4531 - mae: 94.9916 - val_loss: 15387.1709 - val_mae: 78.8811\n",
            "Epoch 50/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21349.1699 - mae: 94.8820 - val_loss: 16303.0029 - val_mae: 81.1838\n",
            "Epoch 51/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21739.6309 - mae: 94.8951 - val_loss: 15649.5205 - val_mae: 79.2325\n",
            "Epoch 52/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 21030.0625 - mae: 93.9516 - val_loss: 14855.2256 - val_mae: 77.6111\n",
            "Epoch 53/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21060.7656 - mae: 93.8969 - val_loss: 14481.1396 - val_mae: 75.8121\n",
            "Epoch 54/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21157.1758 - mae: 93.5709 - val_loss: 14108.4619 - val_mae: 74.8898\n",
            "Epoch 55/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20941.4531 - mae: 93.4354 - val_loss: 13889.9189 - val_mae: 74.5774\n",
            "Epoch 56/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 20690.8477 - mae: 93.5617 - val_loss: 15421.8018 - val_mae: 78.7936\n",
            "Epoch 57/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 21146.5508 - mae: 94.0855 - val_loss: 15593.0098 - val_mae: 78.9172\n",
            "Epoch 58/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20325.0703 - mae: 92.6805 - val_loss: 14047.7070 - val_mae: 75.2786\n",
            "Epoch 59/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20340.5117 - mae: 92.3750 - val_loss: 14884.2627 - val_mae: 77.3942\n",
            "Epoch 60/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 19943.6465 - mae: 91.9534 - val_loss: 14307.0625 - val_mae: 75.1294\n",
            "Epoch 61/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20483.5840 - mae: 92.1041 - val_loss: 13677.8203 - val_mae: 73.9509\n",
            "Epoch 62/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20157.6484 - mae: 92.1539 - val_loss: 14920.9385 - val_mae: 76.8459\n",
            "Epoch 63/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 19701.5312 - mae: 91.4814 - val_loss: 16146.7539 - val_mae: 80.6246\n",
            "Epoch 64/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 19905.2793 - mae: 91.2434 - val_loss: 13963.1797 - val_mae: 75.0854\n",
            "Epoch 65/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 19434.5977 - mae: 90.4616 - val_loss: 15262.4277 - val_mae: 77.6674\n",
            "Epoch 66/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18985.4102 - mae: 89.4711 - val_loss: 14291.1367 - val_mae: 75.4809\n",
            "Epoch 67/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 19250.3809 - mae: 90.3070 - val_loss: 13621.2275 - val_mae: 74.3227\n",
            "Epoch 68/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 19580.7773 - mae: 90.3246 - val_loss: 13212.1074 - val_mae: 72.4197\n",
            "Epoch 69/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18822.7598 - mae: 89.3446 - val_loss: 15745.7227 - val_mae: 80.1980\n",
            "Epoch 70/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18840.0625 - mae: 89.1561 - val_loss: 15612.0508 - val_mae: 79.0408\n",
            "Epoch 71/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 18578.1367 - mae: 88.8414 - val_loss: 13922.5527 - val_mae: 74.4931\n",
            "Epoch 72/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18456.2168 - mae: 88.5081 - val_loss: 15746.6152 - val_mae: 80.4999\n",
            "Epoch 73/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18862.9121 - mae: 89.4188 - val_loss: 14376.6299 - val_mae: 76.4028\n",
            "Epoch 74/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 18235.2031 - mae: 87.6411 - val_loss: 14164.5420 - val_mae: 75.8284\n",
            "Epoch 75/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 18725.4902 - mae: 88.8301 - val_loss: 13583.8955 - val_mae: 74.8963\n",
            "Epoch 76/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18757.4844 - mae: 89.0636 - val_loss: 13069.6846 - val_mae: 72.8197\n",
            "Epoch 77/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18255.0547 - mae: 87.8472 - val_loss: 13606.5381 - val_mae: 74.9737\n",
            "Epoch 78/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 17988.0977 - mae: 87.0560 - val_loss: 13723.7461 - val_mae: 74.8310\n",
            "Epoch 79/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17569.0645 - mae: 86.1682 - val_loss: 13624.8584 - val_mae: 74.4766\n",
            "Epoch 80/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17484.0059 - mae: 86.1679 - val_loss: 12381.3721 - val_mae: 70.8849\n",
            "Epoch 81/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 18014.4023 - mae: 86.7607 - val_loss: 13011.2197 - val_mae: 73.6724\n",
            "Epoch 82/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 17333.7773 - mae: 85.1982 - val_loss: 12890.3994 - val_mae: 72.8180\n",
            "Epoch 83/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17306.2988 - mae: 85.2514 - val_loss: 14258.5498 - val_mae: 76.5760\n",
            "Epoch 84/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17069.1797 - mae: 84.8837 - val_loss: 13651.3301 - val_mae: 74.7026\n",
            "Epoch 85/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 16721.3516 - mae: 83.8464 - val_loss: 13923.9355 - val_mae: 76.6670\n",
            "Epoch 86/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 16512.2148 - mae: 83.6208 - val_loss: 12520.3877 - val_mae: 71.3380\n",
            "Epoch 87/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 16232.9248 - mae: 83.4535 - val_loss: 12827.7939 - val_mae: 73.0894\n",
            "Epoch 88/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 16468.6035 - mae: 82.9989 - val_loss: 13054.8301 - val_mae: 73.5122\n",
            "Epoch 89/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17086.7988 - mae: 82.9935 - val_loss: 13904.9922 - val_mae: 75.4676\n",
            "Epoch 90/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 15312.5078 - mae: 80.8875 - val_loss: 13586.7891 - val_mae: 75.3900\n",
            "Epoch 91/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15919.6621 - mae: 82.1185 - val_loss: 12553.9580 - val_mae: 73.0700\n",
            "Epoch 92/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15556.9824 - mae: 81.8607 - val_loss: 12830.7812 - val_mae: 72.9385\n",
            "Epoch 93/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 15959.6250 - mae: 82.1312 - val_loss: 11248.1738 - val_mae: 68.5224\n",
            "Epoch 94/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15625.2959 - mae: 81.2538 - val_loss: 11225.1533 - val_mae: 68.6261\n",
            "Epoch 95/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15255.9297 - mae: 80.5282 - val_loss: 13764.8467 - val_mae: 76.2951\n",
            "Epoch 96/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15332.2637 - mae: 80.5702 - val_loss: 11414.3584 - val_mae: 69.4593\n",
            "Epoch 97/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 15622.9580 - mae: 81.0995 - val_loss: 10662.0664 - val_mae: 66.3995\n",
            "Epoch 98/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 15146.4561 - mae: 80.3096 - val_loss: 14389.5215 - val_mae: 77.6176\n",
            "Epoch 99/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 15303.6846 - mae: 80.4501 - val_loss: 10832.0244 - val_mae: 67.3766\n",
            "Epoch 100/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 14655.0254 - mae: 79.1562 - val_loss: 12467.6279 - val_mae: 71.8158\n",
            "Epoch 101/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 14809.9766 - mae: 79.7861 - val_loss: 11835.4873 - val_mae: 70.8528\n",
            "Epoch 102/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14792.8848 - mae: 79.3672 - val_loss: 12715.4453 - val_mae: 72.2489\n",
            "Epoch 103/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14721.6074 - mae: 79.5955 - val_loss: 14321.9443 - val_mae: 78.0769\n",
            "Epoch 104/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 14624.3027 - mae: 79.0253 - val_loss: 10436.4277 - val_mae: 66.3195\n",
            "Epoch 105/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14821.4707 - mae: 79.0318 - val_loss: 12922.7070 - val_mae: 73.5921\n",
            "Epoch 106/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 14535.5674 - mae: 78.8301 - val_loss: 12234.1387 - val_mae: 72.2613\n",
            "Epoch 107/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 14375.8867 - mae: 78.0155 - val_loss: 11784.7412 - val_mae: 70.0355\n",
            "Epoch 108/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13962.7236 - mae: 77.5726 - val_loss: 11791.2695 - val_mae: 70.4204\n",
            "Epoch 109/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14516.5811 - mae: 78.5670 - val_loss: 11464.1113 - val_mae: 68.9769\n",
            "Epoch 110/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14328.2373 - mae: 78.1164 - val_loss: 12495.0215 - val_mae: 72.7036\n",
            "Epoch 111/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 14162.5391 - mae: 77.7768 - val_loss: 10837.6230 - val_mae: 67.0377\n",
            "Epoch 112/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14118.3086 - mae: 77.6868 - val_loss: 12327.7715 - val_mae: 72.1196\n",
            "Epoch 113/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14084.5674 - mae: 77.2596 - val_loss: 13135.4893 - val_mae: 74.1678\n",
            "Epoch 114/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 13754.2627 - mae: 76.3424 - val_loss: 11373.8359 - val_mae: 68.4836\n",
            "Epoch 115/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13972.0576 - mae: 76.7838 - val_loss: 12538.7559 - val_mae: 72.4388\n",
            "Epoch 116/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13970.8643 - mae: 76.7326 - val_loss: 15042.8379 - val_mae: 80.0564\n",
            "Epoch 117/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 14186.2061 - mae: 77.2808 - val_loss: 12400.5859 - val_mae: 72.0466\n",
            "Epoch 118/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13498.0244 - mae: 76.0604 - val_loss: 11805.1670 - val_mae: 70.2117\n",
            "Epoch 119/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 14104.3125 - mae: 76.2680 - val_loss: 11747.6875 - val_mae: 69.8796\n",
            "Epoch 120/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13613.3311 - mae: 75.9679 - val_loss: 11641.5166 - val_mae: 70.2631\n",
            "Epoch 121/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 13795.3203 - mae: 76.5140 - val_loss: 16740.6152 - val_mae: 85.0773\n",
            "Epoch 122/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13710.3916 - mae: 76.3307 - val_loss: 11190.0127 - val_mae: 68.2352\n",
            "Epoch 123/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13939.1514 - mae: 76.7635 - val_loss: 14515.4102 - val_mae: 78.2098\n",
            "Epoch 124/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 13806.1299 - mae: 75.8500 - val_loss: 10897.7910 - val_mae: 66.9194\n",
            "Epoch 125/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13526.8877 - mae: 75.7200 - val_loss: 11247.6504 - val_mae: 68.8008\n",
            "Epoch 126/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13828.2646 - mae: 76.3565 - val_loss: 11901.9980 - val_mae: 70.6144\n",
            "Epoch 127/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13662.1826 - mae: 75.6043 - val_loss: 11765.1201 - val_mae: 69.9784\n",
            "Epoch 128/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13314.6299 - mae: 75.1705 - val_loss: 12548.5146 - val_mae: 72.5140\n",
            "Epoch 129/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13541.6406 - mae: 75.6987 - val_loss: 12932.7129 - val_mae: 74.0449\n",
            "Epoch 130/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13437.0791 - mae: 75.1097 - val_loss: 13543.3936 - val_mae: 74.5939\n",
            "Epoch 131/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13287.7617 - mae: 74.9211 - val_loss: 14454.1025 - val_mae: 78.0150\n",
            "Epoch 132/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13316.8711 - mae: 74.9628 - val_loss: 11789.0498 - val_mae: 70.3954\n",
            "Epoch 133/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13250.4785 - mae: 74.9599 - val_loss: 12569.6738 - val_mae: 71.7171\n",
            "Epoch 134/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13117.7969 - mae: 75.0752 - val_loss: 11412.3623 - val_mae: 69.1048\n",
            "Epoch 135/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12848.8711 - mae: 73.9241 - val_loss: 13015.4492 - val_mae: 74.0780\n",
            "Epoch 136/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13389.7334 - mae: 75.4155 - val_loss: 12957.2158 - val_mae: 73.9003\n",
            "Epoch 137/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 13267.9746 - mae: 74.8305 - val_loss: 12206.1094 - val_mae: 70.8752\n",
            "Epoch 138/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12942.5068 - mae: 74.1243 - val_loss: 12061.4678 - val_mae: 70.8958\n",
            "Epoch 139/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13208.8887 - mae: 74.6928 - val_loss: 12673.3418 - val_mae: 72.4096\n",
            "Epoch 140/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13134.2051 - mae: 74.7667 - val_loss: 13090.7422 - val_mae: 73.6687\n",
            "Epoch 141/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 13200.3574 - mae: 74.8233 - val_loss: 14138.4863 - val_mae: 76.7019\n",
            "Epoch 142/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12734.9580 - mae: 74.0390 - val_loss: 12560.2588 - val_mae: 72.4284\n",
            "Epoch 143/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12942.3564 - mae: 73.8830 - val_loss: 11884.1250 - val_mae: 69.0698\n",
            "Epoch 144/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 13015.7832 - mae: 74.4370 - val_loss: 13528.9658 - val_mae: 74.1327\n",
            "Epoch 145/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12964.3965 - mae: 74.2501 - val_loss: 11322.1582 - val_mae: 68.2914\n",
            "Epoch 146/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12746.1826 - mae: 73.5187 - val_loss: 11693.1055 - val_mae: 70.1939\n",
            "Epoch 147/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12758.1406 - mae: 73.5945 - val_loss: 14085.8408 - val_mae: 76.4796\n",
            "Epoch 148/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 13035.6484 - mae: 74.2053 - val_loss: 15495.8486 - val_mae: 80.9361\n",
            "Epoch 149/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12900.1641 - mae: 73.3101 - val_loss: 10868.8389 - val_mae: 67.0875\n",
            "Epoch 150/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12692.7734 - mae: 73.5391 - val_loss: 13328.8838 - val_mae: 74.2094\n",
            "Epoch 151/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12846.1621 - mae: 74.1774 - val_loss: 11651.0635 - val_mae: 68.5468\n",
            "Epoch 152/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12373.9658 - mae: 73.1394 - val_loss: 13294.8223 - val_mae: 73.7748\n",
            "Epoch 153/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12374.3115 - mae: 72.8392 - val_loss: 11589.8291 - val_mae: 69.3951\n",
            "Epoch 154/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12853.1133 - mae: 73.7229 - val_loss: 11073.0605 - val_mae: 67.2867\n",
            "Epoch 155/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12761.7812 - mae: 73.2813 - val_loss: 11524.4307 - val_mae: 69.0794\n",
            "Epoch 156/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12473.6875 - mae: 72.3438 - val_loss: 11662.0400 - val_mae: 69.8823\n",
            "Epoch 157/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12300.6455 - mae: 72.6655 - val_loss: 12253.9395 - val_mae: 71.1078\n",
            "Epoch 158/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12672.6504 - mae: 73.0305 - val_loss: 12845.8936 - val_mae: 72.6643\n",
            "Epoch 159/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12366.3789 - mae: 72.3731 - val_loss: 14372.1338 - val_mae: 76.4010\n",
            "Epoch 160/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12546.0859 - mae: 72.4946 - val_loss: 14153.0889 - val_mae: 75.3824\n",
            "Epoch 161/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12689.5879 - mae: 73.2409 - val_loss: 12775.6250 - val_mae: 72.0895\n",
            "Epoch 162/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12580.5059 - mae: 73.0597 - val_loss: 12854.1875 - val_mae: 72.6069\n",
            "Epoch 163/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12104.9219 - mae: 72.1430 - val_loss: 14255.3174 - val_mae: 75.7010\n",
            "Epoch 164/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12804.8271 - mae: 73.0746 - val_loss: 12138.7373 - val_mae: 70.3269\n",
            "Epoch 165/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12629.6436 - mae: 73.0709 - val_loss: 12715.8057 - val_mae: 72.3238\n",
            "Epoch 166/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12340.8115 - mae: 72.1588 - val_loss: 13200.8867 - val_mae: 73.9606\n",
            "Epoch 167/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12207.3623 - mae: 71.8869 - val_loss: 13881.1592 - val_mae: 74.9018\n",
            "Epoch 168/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 12281.8008 - mae: 71.9115 - val_loss: 14132.4229 - val_mae: 76.6835\n",
            "Epoch 169/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12097.9844 - mae: 71.9199 - val_loss: 11717.2354 - val_mae: 69.1730\n",
            "Epoch 170/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12267.4639 - mae: 72.2627 - val_loss: 12025.3301 - val_mae: 70.0031\n",
            "Epoch 171/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12336.2764 - mae: 71.8246 - val_loss: 12367.4346 - val_mae: 71.4545\n",
            "Epoch 172/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12208.6240 - mae: 72.0601 - val_loss: 13899.6729 - val_mae: 75.8927\n",
            "Epoch 173/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12426.4912 - mae: 72.3043 - val_loss: 14013.6133 - val_mae: 76.1581\n",
            "Epoch 174/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12427.3994 - mae: 72.7213 - val_loss: 13635.9922 - val_mae: 74.8058\n",
            "Epoch 175/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12127.7441 - mae: 71.6225 - val_loss: 12215.3164 - val_mae: 70.2435\n",
            "Epoch 176/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12223.3301 - mae: 72.0184 - val_loss: 15622.6787 - val_mae: 79.5183\n",
            "Epoch 177/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12146.1953 - mae: 71.6245 - val_loss: 15061.0977 - val_mae: 78.6366\n",
            "Epoch 178/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12233.9912 - mae: 71.7348 - val_loss: 13532.9248 - val_mae: 74.4050\n",
            "Epoch 179/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 12033.7285 - mae: 71.4110 - val_loss: 12177.4043 - val_mae: 69.7334\n",
            "Epoch 180/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12262.8174 - mae: 72.1798 - val_loss: 13745.2598 - val_mae: 74.9466\n",
            "Epoch 181/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 12126.7637 - mae: 71.2612 - val_loss: 12938.8994 - val_mae: 72.9218\n",
            "Epoch 182/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11934.1035 - mae: 71.1258 - val_loss: 13255.6621 - val_mae: 73.2517\n",
            "Epoch 183/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11755.5537 - mae: 70.6966 - val_loss: 14242.7217 - val_mae: 76.0503\n",
            "Epoch 184/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11934.0000 - mae: 70.7602 - val_loss: 12190.0508 - val_mae: 70.7301\n",
            "Epoch 185/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11684.7998 - mae: 70.4499 - val_loss: 14132.0840 - val_mae: 75.6209\n",
            "Epoch 186/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11916.1680 - mae: 71.0927 - val_loss: 14227.7500 - val_mae: 76.2862\n",
            "Epoch 187/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12036.8232 - mae: 71.3965 - val_loss: 13774.5137 - val_mae: 75.8505\n",
            "Epoch 188/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11816.8652 - mae: 70.8194 - val_loss: 13340.4922 - val_mae: 74.7715\n",
            "Epoch 189/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11951.3945 - mae: 70.9068 - val_loss: 14688.9502 - val_mae: 76.6480\n",
            "Epoch 190/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 11856.4004 - mae: 70.5620 - val_loss: 13081.8262 - val_mae: 73.2580\n",
            "Epoch 191/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11939.2578 - mae: 71.0958 - val_loss: 13001.9307 - val_mae: 72.9013\n",
            "Epoch 192/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12034.2383 - mae: 71.6810 - val_loss: 12915.2051 - val_mae: 72.4451\n",
            "Epoch 193/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12041.3965 - mae: 71.0981 - val_loss: 13323.0098 - val_mae: 74.3350\n",
            "Epoch 194/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11623.5303 - mae: 70.3694 - val_loss: 14407.6895 - val_mae: 76.0866\n",
            "Epoch 195/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11951.8115 - mae: 70.8361 - val_loss: 12724.4531 - val_mae: 72.2173\n",
            "Epoch 196/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12010.3340 - mae: 71.0055 - val_loss: 12369.1416 - val_mae: 71.0320\n",
            "Epoch 197/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11732.0947 - mae: 70.4316 - val_loss: 14467.0117 - val_mae: 76.9587\n",
            "Epoch 198/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11763.7227 - mae: 70.2780 - val_loss: 13916.6416 - val_mae: 75.9671\n",
            "Epoch 199/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 12084.6709 - mae: 70.8197 - val_loss: 13933.2383 - val_mae: 75.7404\n",
            "Epoch 200/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11849.2461 - mae: 70.7536 - val_loss: 14472.2021 - val_mae: 77.6108\n",
            "Epoch 201/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 11701.9033 - mae: 70.0547 - val_loss: 13986.7002 - val_mae: 76.3369\n",
            "Epoch 202/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11623.9619 - mae: 70.0209 - val_loss: 14475.6709 - val_mae: 77.0035\n",
            "Epoch 203/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11841.1084 - mae: 70.2779 - val_loss: 11797.9658 - val_mae: 69.7568\n",
            "Epoch 204/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11556.1006 - mae: 69.9077 - val_loss: 13880.5811 - val_mae: 75.7155\n",
            "Epoch 205/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11714.2607 - mae: 70.0523 - val_loss: 13726.9736 - val_mae: 74.7934\n",
            "Epoch 206/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11702.2998 - mae: 70.6418 - val_loss: 11976.3438 - val_mae: 69.7849\n",
            "Epoch 207/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11769.6494 - mae: 70.3529 - val_loss: 12864.7930 - val_mae: 72.6578\n",
            "Epoch 208/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11288.9639 - mae: 69.2319 - val_loss: 14726.0693 - val_mae: 77.7261\n",
            "Epoch 209/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11770.9902 - mae: 70.4025 - val_loss: 13287.9854 - val_mae: 73.8725\n",
            "Epoch 210/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11696.6045 - mae: 70.1962 - val_loss: 11804.6934 - val_mae: 69.5771\n",
            "Epoch 211/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11578.4131 - mae: 69.9526 - val_loss: 14456.3945 - val_mae: 77.2745\n",
            "Epoch 212/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11451.0332 - mae: 69.8078 - val_loss: 12269.1123 - val_mae: 70.7412\n",
            "Epoch 213/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11659.4160 - mae: 69.9815 - val_loss: 12946.5596 - val_mae: 72.2043\n",
            "Epoch 214/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11458.2803 - mae: 69.8528 - val_loss: 11911.0127 - val_mae: 70.7491\n",
            "Epoch 215/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11593.9473 - mae: 70.1222 - val_loss: 13170.6826 - val_mae: 73.5311\n",
            "Epoch 216/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11499.6289 - mae: 69.6916 - val_loss: 13708.3545 - val_mae: 75.4695\n",
            "Epoch 217/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 11434.0723 - mae: 69.7088 - val_loss: 13595.5420 - val_mae: 75.5713\n",
            "Epoch 218/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11714.2793 - mae: 69.8902 - val_loss: 12734.2617 - val_mae: 72.0932\n",
            "Epoch 219/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11645.6934 - mae: 70.0653 - val_loss: 14829.4873 - val_mae: 78.3175\n",
            "Epoch 220/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11512.3711 - mae: 70.0908 - val_loss: 14376.2568 - val_mae: 76.3908\n",
            "Epoch 221/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11568.9082 - mae: 70.0602 - val_loss: 13142.8125 - val_mae: 74.1550\n",
            "Epoch 222/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11543.7080 - mae: 69.8837 - val_loss: 11549.9619 - val_mae: 68.5672\n",
            "Epoch 223/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11313.8672 - mae: 69.2139 - val_loss: 12920.8760 - val_mae: 73.4837\n",
            "Epoch 224/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11507.3721 - mae: 69.8331 - val_loss: 13334.0625 - val_mae: 74.0803\n",
            "Epoch 225/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11386.8867 - mae: 69.6147 - val_loss: 12620.4258 - val_mae: 72.2355\n",
            "Epoch 226/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11872.1387 - mae: 70.2226 - val_loss: 14043.3965 - val_mae: 76.2599\n",
            "Epoch 227/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11517.9814 - mae: 69.7512 - val_loss: 12525.2402 - val_mae: 71.4257\n",
            "Epoch 228/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11643.7031 - mae: 69.6548 - val_loss: 13606.6992 - val_mae: 75.1295\n",
            "Epoch 229/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11536.8262 - mae: 69.6823 - val_loss: 13174.5996 - val_mae: 73.5115\n",
            "Epoch 230/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11386.1875 - mae: 69.6734 - val_loss: 12752.2158 - val_mae: 71.2974\n",
            "Epoch 231/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11215.3252 - mae: 69.3961 - val_loss: 13231.6416 - val_mae: 74.3154\n",
            "Epoch 232/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11433.3242 - mae: 69.3255 - val_loss: 14968.2295 - val_mae: 78.6272\n",
            "Epoch 233/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11310.2314 - mae: 69.5567 - val_loss: 14552.1074 - val_mae: 77.9055\n",
            "Epoch 234/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11420.1162 - mae: 69.4212 - val_loss: 13991.1709 - val_mae: 75.4835\n",
            "Epoch 235/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11514.4229 - mae: 69.6267 - val_loss: 13460.8516 - val_mae: 74.2450\n",
            "Epoch 236/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11458.0420 - mae: 69.6673 - val_loss: 14396.4209 - val_mae: 76.1782\n",
            "Epoch 237/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11374.8242 - mae: 69.2626 - val_loss: 12838.8975 - val_mae: 71.4430\n",
            "Epoch 238/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11409.0586 - mae: 69.4765 - val_loss: 13619.0674 - val_mae: 75.3168\n",
            "Epoch 239/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11357.7783 - mae: 69.5131 - val_loss: 13430.2568 - val_mae: 73.7952\n",
            "Epoch 240/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11276.2666 - mae: 69.4075 - val_loss: 13536.2549 - val_mae: 74.9752\n",
            "Epoch 241/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11207.8145 - mae: 68.7826 - val_loss: 13958.0244 - val_mae: 75.3870\n",
            "Epoch 242/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11349.3652 - mae: 69.0920 - val_loss: 14663.9873 - val_mae: 78.1941\n",
            "Epoch 243/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11308.3076 - mae: 69.2588 - val_loss: 13054.4961 - val_mae: 73.0071\n",
            "Epoch 244/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 11126.1592 - mae: 68.8001 - val_loss: 11694.2881 - val_mae: 68.8464\n",
            "Epoch 245/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 11176.6562 - mae: 68.3710 - val_loss: 14487.5898 - val_mae: 77.4494\n",
            "Epoch 246/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11443.6768 - mae: 69.3975 - val_loss: 13211.1992 - val_mae: 73.3541\n",
            "Epoch 247/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11329.8994 - mae: 69.2474 - val_loss: 12960.1299 - val_mae: 72.8622\n",
            "Epoch 248/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 11090.9365 - mae: 68.5697 - val_loss: 15717.1777 - val_mae: 79.6167\n",
            "Epoch 249/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 11344.6348 - mae: 69.3041 - val_loss: 12029.3975 - val_mae: 69.8856\n",
            "Epoch 250/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 10941.0889 - mae: 68.5428 - val_loss: 15759.1113 - val_mae: 80.1239\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 16062.4053 - mae: 80.8460\n",
            "Test MAE: 80.64\n",
            "\u001b[1m3515/3515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1c19b4f"
      },
      "source": [
        "# Task\n",
        "Improve the model's performance in the notebook \"/content/module04_biking_grading.ipynb\" by iterating on the model architecture, hyperparameters, feature engineering, and regularization techniques, evaluating the results using the provided metrics (Within 5%, Within 10%, Within 20%, R^2, RMSE, MAE, MedAE) after each change, and summarizing the changes and results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603247c3"
      },
      "source": [
        "## Revisar la arquitectura del modelo\n",
        "\n",
        "### Subtask:\n",
        "Experimentar con un número diferente de capas densas y neuronas en cada capa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9960693"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the model architecture with a different number of dense layers and neurons, keeping the input shape and the output layer the same, and then train and evaluate the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a61bd342",
        "outputId": "160bb914-86be-4081-bfd4-a402dc1624b7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=250,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {mae:.2f}\")\n",
        "\n",
        "# Predictions\n",
        "bikes[\"predicted_total\"] = model.predict(scaler.transform(X))\n",
        "\n",
        "# Save only the first 384 predictions as 'total_rentals'\n",
        "bikes[\"predicted_total\"].head(384).to_csv(\"bike-predictions.csv\", index=False, header=['total_rentals'])\n",
        "print(\"✅ CSV export complete!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 110175.4062 - mae: 229.2974 - val_loss: 62159.2656 - val_mae: 172.8886\n",
            "Epoch 2/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 53219.5312 - mae: 156.8279 - val_loss: 40562.3008 - val_mae: 129.8511\n",
            "Epoch 3/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 38741.4180 - mae: 128.1618 - val_loss: 29645.1699 - val_mae: 112.0340\n",
            "Epoch 4/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 27637.4531 - mae: 107.9575 - val_loss: 21807.0801 - val_mae: 95.0055\n",
            "Epoch 5/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 20803.1855 - mae: 94.4149 - val_loss: 19348.3184 - val_mae: 92.7008\n",
            "Epoch 6/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 17799.8555 - mae: 87.1144 - val_loss: 16980.7637 - val_mae: 84.7362\n",
            "Epoch 7/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 16104.8828 - mae: 83.0080 - val_loss: 15006.5811 - val_mae: 80.0979\n",
            "Epoch 8/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 14697.6016 - mae: 78.8328 - val_loss: 17068.0664 - val_mae: 84.9431\n",
            "Epoch 9/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 13843.3506 - mae: 76.9115 - val_loss: 12969.3770 - val_mae: 74.6404\n",
            "Epoch 10/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 12606.6758 - mae: 73.6329 - val_loss: 12810.9316 - val_mae: 73.7604\n",
            "Epoch 11/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 12164.2393 - mae: 71.9576 - val_loss: 11595.5742 - val_mae: 70.3100\n",
            "Epoch 12/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11373.0625 - mae: 70.1157 - val_loss: 11195.3633 - val_mae: 68.6344\n",
            "Epoch 13/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11278.8818 - mae: 69.4244 - val_loss: 10825.9863 - val_mae: 67.6273\n",
            "Epoch 14/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 10854.2031 - mae: 68.0903 - val_loss: 10497.8516 - val_mae: 67.1999\n",
            "Epoch 15/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10331.9062 - mae: 66.4214 - val_loss: 10293.0537 - val_mae: 66.5135\n",
            "Epoch 16/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10318.5186 - mae: 65.9072 - val_loss: 10873.0215 - val_mae: 67.6575\n",
            "Epoch 17/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10097.2920 - mae: 65.7311 - val_loss: 10328.6582 - val_mae: 66.0644\n",
            "Epoch 18/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 9938.4150 - mae: 64.6229 - val_loss: 9547.0684 - val_mae: 63.3645\n",
            "Epoch 19/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 9580.1113 - mae: 63.5793 - val_loss: 11281.6943 - val_mae: 68.6772\n",
            "Epoch 20/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9490.9043 - mae: 63.0669 - val_loss: 9227.1826 - val_mae: 62.4818\n",
            "Epoch 21/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 9566.0635 - mae: 63.2296 - val_loss: 9082.7686 - val_mae: 61.7247\n",
            "Epoch 22/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 9027.7285 - mae: 61.5045 - val_loss: 9673.0820 - val_mae: 63.4188\n",
            "Epoch 23/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8986.8037 - mae: 61.2229 - val_loss: 9388.3184 - val_mae: 62.7243\n",
            "Epoch 24/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8894.9971 - mae: 60.6022 - val_loss: 9953.5947 - val_mae: 65.3188\n",
            "Epoch 25/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8777.0635 - mae: 60.0146 - val_loss: 8685.1289 - val_mae: 60.0398\n",
            "Epoch 26/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8544.1328 - mae: 59.3253 - val_loss: 9747.6191 - val_mae: 62.9092\n",
            "Epoch 27/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8596.6523 - mae: 59.5004 - val_loss: 8962.9766 - val_mae: 60.6897\n",
            "Epoch 28/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8671.0234 - mae: 59.5152 - val_loss: 8542.5527 - val_mae: 59.3848\n",
            "Epoch 29/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8328.0635 - mae: 58.5126 - val_loss: 8521.9551 - val_mae: 58.7376\n",
            "Epoch 30/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8472.5986 - mae: 58.1147 - val_loss: 8211.0820 - val_mae: 57.6531\n",
            "Epoch 31/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 8132.4624 - mae: 57.6129 - val_loss: 8203.3027 - val_mae: 57.1157\n",
            "Epoch 32/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 8165.5024 - mae: 57.7806 - val_loss: 8457.1133 - val_mae: 58.8306\n",
            "Epoch 33/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8107.7295 - mae: 57.1374 - val_loss: 8254.8477 - val_mae: 57.7017\n",
            "Epoch 34/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8076.3271 - mae: 57.0378 - val_loss: 8068.9619 - val_mae: 56.8096\n",
            "Epoch 35/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 8166.8872 - mae: 57.4608 - val_loss: 8630.4268 - val_mae: 59.4579\n",
            "Epoch 36/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8055.1582 - mae: 56.8295 - val_loss: 8317.5703 - val_mae: 57.9753\n",
            "Epoch 37/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8118.0269 - mae: 56.8165 - val_loss: 7994.0503 - val_mae: 56.4115\n",
            "Epoch 38/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8129.9663 - mae: 56.9696 - val_loss: 7775.2788 - val_mae: 55.8961\n",
            "Epoch 39/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 8051.8169 - mae: 56.6827 - val_loss: 8094.0991 - val_mae: 56.5536\n",
            "Epoch 40/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7882.6187 - mae: 56.5831 - val_loss: 8026.5430 - val_mae: 57.0085\n",
            "Epoch 41/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7896.2437 - mae: 56.2692 - val_loss: 7855.0146 - val_mae: 56.1480\n",
            "Epoch 42/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7669.9214 - mae: 55.8149 - val_loss: 7834.0981 - val_mae: 55.8235\n",
            "Epoch 43/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7696.0420 - mae: 55.8418 - val_loss: 8173.5708 - val_mae: 57.2137\n",
            "Epoch 44/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7960.3398 - mae: 56.1982 - val_loss: 8021.3755 - val_mae: 56.8816\n",
            "Epoch 45/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7806.7881 - mae: 55.8476 - val_loss: 7661.6973 - val_mae: 55.4203\n",
            "Epoch 46/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7502.9746 - mae: 55.0697 - val_loss: 7939.2461 - val_mae: 56.6854\n",
            "Epoch 47/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7718.3296 - mae: 55.6752 - val_loss: 8030.7373 - val_mae: 56.5207\n",
            "Epoch 48/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7683.1475 - mae: 55.5410 - val_loss: 7843.8594 - val_mae: 55.7966\n",
            "Epoch 49/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 7611.4126 - mae: 55.1023 - val_loss: 8059.0522 - val_mae: 56.7551\n",
            "Epoch 50/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7718.1758 - mae: 55.5044 - val_loss: 8043.0498 - val_mae: 56.8278\n",
            "Epoch 51/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7566.0605 - mae: 55.4586 - val_loss: 7730.6147 - val_mae: 55.7849\n",
            "Epoch 52/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7558.4663 - mae: 54.7798 - val_loss: 7749.8145 - val_mae: 55.6115\n",
            "Epoch 53/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7504.3247 - mae: 55.1343 - val_loss: 7749.5586 - val_mae: 55.8199\n",
            "Epoch 54/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7585.4692 - mae: 55.2131 - val_loss: 7624.5308 - val_mae: 55.2464\n",
            "Epoch 55/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7389.9224 - mae: 54.4530 - val_loss: 7966.5571 - val_mae: 56.8973\n",
            "Epoch 56/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7240.7583 - mae: 54.3400 - val_loss: 7516.9629 - val_mae: 55.1570\n",
            "Epoch 57/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7417.5684 - mae: 54.5391 - val_loss: 7861.7407 - val_mae: 55.8596\n",
            "Epoch 58/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7403.3926 - mae: 54.1929 - val_loss: 9327.5664 - val_mae: 60.9774\n",
            "Epoch 59/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7457.9429 - mae: 54.6981 - val_loss: 7389.7666 - val_mae: 54.0634\n",
            "Epoch 60/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7294.4272 - mae: 54.0429 - val_loss: 7416.0913 - val_mae: 53.8879\n",
            "Epoch 61/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7471.8662 - mae: 54.4931 - val_loss: 7925.6899 - val_mae: 56.5689\n",
            "Epoch 62/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7374.2461 - mae: 54.1129 - val_loss: 7420.7944 - val_mae: 54.0183\n",
            "Epoch 63/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7353.8525 - mae: 54.2082 - val_loss: 9484.7441 - val_mae: 61.4759\n",
            "Epoch 64/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7432.3916 - mae: 54.5060 - val_loss: 7504.1128 - val_mae: 54.8331\n",
            "Epoch 65/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7218.4253 - mae: 53.9471 - val_loss: 7766.1523 - val_mae: 55.8299\n",
            "Epoch 66/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7488.4634 - mae: 54.4272 - val_loss: 7710.8584 - val_mae: 55.1632\n",
            "Epoch 67/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7048.3467 - mae: 53.2200 - val_loss: 8011.1445 - val_mae: 57.5221\n",
            "Epoch 68/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7268.9775 - mae: 53.8867 - val_loss: 8088.7114 - val_mae: 56.8710\n",
            "Epoch 69/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7230.3311 - mae: 53.9518 - val_loss: 7716.0908 - val_mae: 55.4635\n",
            "Epoch 70/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7334.3052 - mae: 53.7889 - val_loss: 7465.5229 - val_mae: 54.1659\n",
            "Epoch 71/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7027.2905 - mae: 53.0828 - val_loss: 7706.9253 - val_mae: 55.2876\n",
            "Epoch 72/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7078.8545 - mae: 53.3574 - val_loss: 7396.3486 - val_mae: 54.1124\n",
            "Epoch 73/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6988.1641 - mae: 52.8990 - val_loss: 7597.8091 - val_mae: 55.1768\n",
            "Epoch 74/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7260.4888 - mae: 53.7725 - val_loss: 7796.4819 - val_mae: 55.5487\n",
            "Epoch 75/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7019.0171 - mae: 52.9562 - val_loss: 8170.4663 - val_mae: 57.0154\n",
            "Epoch 76/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7086.3086 - mae: 53.5780 - val_loss: 7376.4233 - val_mae: 54.3713\n",
            "Epoch 77/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7171.2036 - mae: 53.5418 - val_loss: 7347.4419 - val_mae: 53.8068\n",
            "Epoch 78/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6954.9570 - mae: 52.7420 - val_loss: 7482.5928 - val_mae: 54.2755\n",
            "Epoch 79/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7094.1470 - mae: 52.9908 - val_loss: 7330.1792 - val_mae: 53.7880\n",
            "Epoch 80/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7296.1968 - mae: 53.5942 - val_loss: 7324.1357 - val_mae: 53.8407\n",
            "Epoch 81/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7046.1602 - mae: 53.0361 - val_loss: 7391.6323 - val_mae: 53.5144\n",
            "Epoch 82/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7138.7568 - mae: 53.3335 - val_loss: 7236.6597 - val_mae: 53.4197\n",
            "Epoch 83/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 7008.6807 - mae: 52.9624 - val_loss: 7335.3286 - val_mae: 54.1001\n",
            "Epoch 84/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6932.3247 - mae: 52.8193 - val_loss: 7154.2974 - val_mae: 52.8892\n",
            "Epoch 85/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7062.3096 - mae: 53.1747 - val_loss: 7535.3208 - val_mae: 54.5690\n",
            "Epoch 86/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6924.9028 - mae: 52.6030 - val_loss: 7390.4092 - val_mae: 54.8034\n",
            "Epoch 87/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6847.0493 - mae: 52.4612 - val_loss: 7766.1509 - val_mae: 55.5776\n",
            "Epoch 88/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6991.3564 - mae: 52.7099 - val_loss: 7317.3174 - val_mae: 53.6885\n",
            "Epoch 89/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6964.9956 - mae: 52.8336 - val_loss: 7153.9927 - val_mae: 53.3793\n",
            "Epoch 90/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6793.3384 - mae: 52.5215 - val_loss: 7522.7319 - val_mae: 54.3768\n",
            "Epoch 91/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6814.7842 - mae: 52.5008 - val_loss: 7639.7964 - val_mae: 55.2536\n",
            "Epoch 92/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 7007.2778 - mae: 52.7718 - val_loss: 7261.2231 - val_mae: 53.6766\n",
            "Epoch 93/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6927.3008 - mae: 52.5431 - val_loss: 7164.4839 - val_mae: 52.6954\n",
            "Epoch 94/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7009.0605 - mae: 52.9453 - val_loss: 7678.8354 - val_mae: 55.3591\n",
            "Epoch 95/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7036.1714 - mae: 53.2110 - val_loss: 7203.1650 - val_mae: 53.2405\n",
            "Epoch 96/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6680.6318 - mae: 51.7931 - val_loss: 7328.1660 - val_mae: 53.8562\n",
            "Epoch 97/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6757.2656 - mae: 52.3277 - val_loss: 7425.1084 - val_mae: 54.4292\n",
            "Epoch 98/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6870.2207 - mae: 52.3631 - val_loss: 7056.4497 - val_mae: 52.9652\n",
            "Epoch 99/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6838.3931 - mae: 52.2470 - val_loss: 7127.7407 - val_mae: 52.8841\n",
            "Epoch 100/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6803.6792 - mae: 52.2269 - val_loss: 7256.0288 - val_mae: 53.6164\n",
            "Epoch 101/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6829.1426 - mae: 52.4616 - val_loss: 7473.3276 - val_mae: 54.7203\n",
            "Epoch 102/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6965.1387 - mae: 52.6188 - val_loss: 7372.9185 - val_mae: 54.0680\n",
            "Epoch 103/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6828.0420 - mae: 52.1758 - val_loss: 7291.3833 - val_mae: 53.6583\n",
            "Epoch 104/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7021.8477 - mae: 52.8733 - val_loss: 7373.3530 - val_mae: 54.1423\n",
            "Epoch 105/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6745.2427 - mae: 52.1007 - val_loss: 7797.0420 - val_mae: 56.0325\n",
            "Epoch 106/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6766.0210 - mae: 51.8530 - val_loss: 7127.1094 - val_mae: 53.2309\n",
            "Epoch 107/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 6832.6162 - mae: 52.1686 - val_loss: 6912.4106 - val_mae: 52.2718\n",
            "Epoch 108/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6588.0615 - mae: 51.3357 - val_loss: 7412.8433 - val_mae: 53.6900\n",
            "Epoch 109/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6855.0776 - mae: 52.1339 - val_loss: 7458.6289 - val_mae: 54.5882\n",
            "Epoch 110/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6707.7173 - mae: 51.8894 - val_loss: 7039.9165 - val_mae: 52.6742\n",
            "Epoch 111/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6645.0249 - mae: 51.5705 - val_loss: 8127.5786 - val_mae: 57.4898\n",
            "Epoch 112/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6710.0518 - mae: 51.8484 - val_loss: 6951.6680 - val_mae: 52.2492\n",
            "Epoch 113/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6754.1748 - mae: 52.1722 - val_loss: 7274.8174 - val_mae: 53.6461\n",
            "Epoch 114/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6657.1133 - mae: 51.6511 - val_loss: 7123.3872 - val_mae: 53.2049\n",
            "Epoch 115/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6862.3599 - mae: 52.1593 - val_loss: 7190.3335 - val_mae: 53.0989\n",
            "Epoch 116/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6595.3936 - mae: 51.2764 - val_loss: 7107.8374 - val_mae: 52.8734\n",
            "Epoch 117/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6617.9155 - mae: 51.5760 - val_loss: 7136.5371 - val_mae: 53.0772\n",
            "Epoch 118/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6686.8042 - mae: 51.6130 - val_loss: 7094.8447 - val_mae: 53.2891\n",
            "Epoch 119/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6577.6777 - mae: 51.4219 - val_loss: 7068.9746 - val_mae: 52.7029\n",
            "Epoch 120/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6652.3789 - mae: 51.7757 - val_loss: 7004.5503 - val_mae: 52.3673\n",
            "Epoch 121/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6535.6030 - mae: 51.3431 - val_loss: 7977.9551 - val_mae: 56.0665\n",
            "Epoch 122/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6585.1543 - mae: 51.4579 - val_loss: 7227.7290 - val_mae: 53.2614\n",
            "Epoch 123/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6494.6416 - mae: 51.3013 - val_loss: 7034.4443 - val_mae: 52.6811\n",
            "Epoch 124/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6664.9604 - mae: 51.6370 - val_loss: 7470.6123 - val_mae: 54.5148\n",
            "Epoch 125/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 6730.2524 - mae: 51.7676 - val_loss: 7515.3921 - val_mae: 54.3052\n",
            "Epoch 126/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6643.4839 - mae: 51.5036 - val_loss: 7256.9150 - val_mae: 53.3927\n",
            "Epoch 127/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6629.4233 - mae: 51.4164 - val_loss: 7325.7207 - val_mae: 54.1566\n",
            "Epoch 128/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6666.1714 - mae: 51.4775 - val_loss: 7396.3022 - val_mae: 54.6476\n",
            "Epoch 129/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6626.3672 - mae: 51.5841 - val_loss: 7420.7368 - val_mae: 54.1804\n",
            "Epoch 130/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6622.6060 - mae: 51.4262 - val_loss: 6977.5303 - val_mae: 52.3453\n",
            "Epoch 131/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6492.0303 - mae: 50.9595 - val_loss: 7150.5854 - val_mae: 52.9340\n",
            "Epoch 132/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6437.9619 - mae: 50.8272 - val_loss: 7095.2656 - val_mae: 52.5486\n",
            "Epoch 133/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6499.1855 - mae: 51.1704 - val_loss: 6926.4443 - val_mae: 51.8512\n",
            "Epoch 134/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6540.6177 - mae: 50.9344 - val_loss: 7407.3389 - val_mae: 53.8756\n",
            "Epoch 135/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6523.5200 - mae: 51.2425 - val_loss: 7327.4141 - val_mae: 53.2885\n",
            "Epoch 136/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6672.8418 - mae: 51.5308 - val_loss: 7487.0361 - val_mae: 54.3581\n",
            "Epoch 137/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6535.4521 - mae: 51.0463 - val_loss: 7151.3760 - val_mae: 53.1452\n",
            "Epoch 138/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6434.5483 - mae: 50.6148 - val_loss: 7078.9941 - val_mae: 52.4295\n",
            "Epoch 139/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6493.2407 - mae: 51.1919 - val_loss: 7479.2993 - val_mae: 55.0128\n",
            "Epoch 140/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6558.8862 - mae: 51.1473 - val_loss: 7587.4077 - val_mae: 54.8445\n",
            "Epoch 141/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6581.8232 - mae: 51.5077 - val_loss: 7012.6196 - val_mae: 52.4426\n",
            "Epoch 142/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6359.9224 - mae: 50.4764 - val_loss: 6985.4448 - val_mae: 52.4483\n",
            "Epoch 143/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6499.7231 - mae: 50.8851 - val_loss: 7493.9097 - val_mae: 54.1974\n",
            "Epoch 144/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6440.6724 - mae: 50.7461 - val_loss: 7215.8906 - val_mae: 53.7239\n",
            "Epoch 145/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6468.5776 - mae: 51.0338 - val_loss: 7123.0518 - val_mae: 53.0848\n",
            "Epoch 146/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6258.3667 - mae: 50.1468 - val_loss: 6974.3726 - val_mae: 52.0374\n",
            "Epoch 147/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6379.6973 - mae: 50.4327 - val_loss: 6963.7495 - val_mae: 52.5803\n",
            "Epoch 148/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6626.6177 - mae: 51.1944 - val_loss: 7073.7559 - val_mae: 52.9548\n",
            "Epoch 149/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6605.6680 - mae: 51.0305 - val_loss: 7316.4795 - val_mae: 53.5874\n",
            "Epoch 150/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6285.7515 - mae: 50.4125 - val_loss: 7031.6455 - val_mae: 52.4530\n",
            "Epoch 151/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6451.9619 - mae: 50.8599 - val_loss: 6894.0425 - val_mae: 52.0188\n",
            "Epoch 152/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6407.4858 - mae: 50.3921 - val_loss: 7040.1162 - val_mae: 52.7550\n",
            "Epoch 153/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6425.8618 - mae: 50.7389 - val_loss: 7314.2725 - val_mae: 53.8087\n",
            "Epoch 154/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6358.1313 - mae: 50.3111 - val_loss: 7742.4849 - val_mae: 55.8947\n",
            "Epoch 155/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6475.0503 - mae: 50.9546 - val_loss: 6870.2065 - val_mae: 52.1255\n",
            "Epoch 156/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6567.4033 - mae: 50.9218 - val_loss: 6934.6860 - val_mae: 52.2595\n",
            "Epoch 157/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6312.6372 - mae: 50.3513 - val_loss: 7241.7305 - val_mae: 53.7043\n",
            "Epoch 158/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6394.2896 - mae: 50.4624 - val_loss: 7411.1572 - val_mae: 54.3634\n",
            "Epoch 159/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6447.6025 - mae: 50.7682 - val_loss: 7237.8188 - val_mae: 53.4335\n",
            "Epoch 160/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6322.2417 - mae: 50.1627 - val_loss: 6938.8320 - val_mae: 52.4992\n",
            "Epoch 161/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6347.8760 - mae: 50.3368 - val_loss: 7145.5557 - val_mae: 52.4215\n",
            "Epoch 162/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6346.9614 - mae: 50.3331 - val_loss: 7085.8481 - val_mae: 52.6517\n",
            "Epoch 163/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6398.3652 - mae: 50.5924 - val_loss: 7151.3940 - val_mae: 52.7676\n",
            "Epoch 164/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6245.0498 - mae: 50.0399 - val_loss: 7044.6504 - val_mae: 52.7528\n",
            "Epoch 165/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6337.7529 - mae: 50.2308 - val_loss: 7238.3203 - val_mae: 53.5106\n",
            "Epoch 166/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6174.0923 - mae: 49.7346 - val_loss: 6806.9404 - val_mae: 51.6737\n",
            "Epoch 167/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6303.5044 - mae: 50.0978 - val_loss: 6864.8740 - val_mae: 52.1480\n",
            "Epoch 168/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6242.8213 - mae: 50.0505 - val_loss: 7530.2256 - val_mae: 54.0305\n",
            "Epoch 169/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6232.5215 - mae: 49.6876 - val_loss: 6923.6001 - val_mae: 52.3452\n",
            "Epoch 170/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6309.6445 - mae: 50.0861 - val_loss: 6977.7266 - val_mae: 52.1861\n",
            "Epoch 171/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6419.6909 - mae: 50.2302 - val_loss: 6826.5229 - val_mae: 51.8362\n",
            "Epoch 172/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6325.2959 - mae: 50.0424 - val_loss: 6957.9263 - val_mae: 52.3739\n",
            "Epoch 173/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6188.9854 - mae: 49.7492 - val_loss: 7604.1763 - val_mae: 54.8824\n",
            "Epoch 174/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6128.3247 - mae: 49.8187 - val_loss: 6770.4409 - val_mae: 51.4834\n",
            "Epoch 175/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6141.8384 - mae: 49.5013 - val_loss: 6745.6362 - val_mae: 51.3746\n",
            "Epoch 176/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6174.4800 - mae: 49.5841 - val_loss: 6691.6201 - val_mae: 51.3178\n",
            "Epoch 177/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6154.4604 - mae: 49.5493 - val_loss: 6844.1201 - val_mae: 51.7915\n",
            "Epoch 178/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6136.3999 - mae: 49.6599 - val_loss: 7850.7417 - val_mae: 54.7090\n",
            "Epoch 179/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6439.2383 - mae: 50.3733 - val_loss: 6880.6763 - val_mae: 51.6381\n",
            "Epoch 180/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6107.2822 - mae: 49.5515 - val_loss: 6925.9131 - val_mae: 52.3701\n",
            "Epoch 181/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6283.4810 - mae: 50.0371 - val_loss: 6808.3896 - val_mae: 51.8586\n",
            "Epoch 182/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6202.8496 - mae: 49.7973 - val_loss: 7189.9780 - val_mae: 53.1409\n",
            "Epoch 183/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6450.3472 - mae: 50.5749 - val_loss: 6827.2891 - val_mae: 51.7094\n",
            "Epoch 184/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6121.9414 - mae: 49.4376 - val_loss: 7445.9429 - val_mae: 55.0123\n",
            "Epoch 185/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6079.8394 - mae: 49.2336 - val_loss: 7077.4663 - val_mae: 53.1083\n",
            "Epoch 186/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6042.0820 - mae: 49.2091 - val_loss: 6880.0342 - val_mae: 52.0897\n",
            "Epoch 187/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6180.6846 - mae: 49.3913 - val_loss: 6784.6943 - val_mae: 51.3971\n",
            "Epoch 188/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6012.1709 - mae: 48.7043 - val_loss: 6856.3579 - val_mae: 51.7744\n",
            "Epoch 189/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6158.8809 - mae: 49.7282 - val_loss: 7109.2158 - val_mae: 52.2970\n",
            "Epoch 190/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6104.5903 - mae: 49.3401 - val_loss: 6976.0903 - val_mae: 52.4059\n",
            "Epoch 191/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6014.1865 - mae: 49.0985 - val_loss: 6883.1836 - val_mae: 51.8383\n",
            "Epoch 192/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6264.7612 - mae: 49.5102 - val_loss: 6754.6123 - val_mae: 51.2666\n",
            "Epoch 193/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6063.1123 - mae: 49.2882 - val_loss: 6757.9048 - val_mae: 51.4288\n",
            "Epoch 194/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5928.7349 - mae: 48.8284 - val_loss: 6772.7563 - val_mae: 51.4161\n",
            "Epoch 195/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6274.2109 - mae: 49.7185 - val_loss: 7152.4194 - val_mae: 52.3948\n",
            "Epoch 196/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6101.1221 - mae: 48.9889 - val_loss: 6716.0137 - val_mae: 51.0831\n",
            "Epoch 197/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5988.0010 - mae: 48.9685 - val_loss: 6856.3301 - val_mae: 51.6393\n",
            "Epoch 198/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6211.9282 - mae: 49.5285 - val_loss: 6840.0698 - val_mae: 51.8171\n",
            "Epoch 199/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6052.7510 - mae: 49.0877 - val_loss: 6860.9331 - val_mae: 51.8722\n",
            "Epoch 200/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6118.5161 - mae: 49.2240 - val_loss: 6634.5532 - val_mae: 50.7300\n",
            "Epoch 201/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5998.7637 - mae: 49.0750 - val_loss: 6760.5444 - val_mae: 51.4886\n",
            "Epoch 202/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5830.8086 - mae: 48.5285 - val_loss: 6781.9175 - val_mae: 51.4401\n",
            "Epoch 203/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5966.7500 - mae: 48.8839 - val_loss: 7077.8350 - val_mae: 53.0316\n",
            "Epoch 204/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6177.4263 - mae: 49.5093 - val_loss: 7207.3530 - val_mae: 53.3409\n",
            "Epoch 205/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6186.4390 - mae: 49.4867 - val_loss: 6726.8774 - val_mae: 51.2470\n",
            "Epoch 206/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5942.6284 - mae: 48.8879 - val_loss: 6737.6104 - val_mae: 51.4947\n",
            "Epoch 207/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 6069.1318 - mae: 49.2180 - val_loss: 6908.2114 - val_mae: 52.1372\n",
            "Epoch 208/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6084.0640 - mae: 49.0630 - val_loss: 7173.9619 - val_mae: 53.3267\n",
            "Epoch 209/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6081.3975 - mae: 48.8730 - val_loss: 6928.8965 - val_mae: 52.3455\n",
            "Epoch 210/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5888.2656 - mae: 48.4539 - val_loss: 6919.1162 - val_mae: 52.4427\n",
            "Epoch 211/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6124.8750 - mae: 48.8922 - val_loss: 6716.8384 - val_mae: 51.6546\n",
            "Epoch 212/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5947.2710 - mae: 48.6842 - val_loss: 6979.5029 - val_mae: 52.7609\n",
            "Epoch 213/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5877.9502 - mae: 48.4217 - val_loss: 6975.8569 - val_mae: 51.9342\n",
            "Epoch 214/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5971.6660 - mae: 48.8838 - val_loss: 6828.2256 - val_mae: 51.1589\n",
            "Epoch 215/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5832.0039 - mae: 48.5526 - val_loss: 6714.2222 - val_mae: 51.3062\n",
            "Epoch 216/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6084.4712 - mae: 49.2618 - val_loss: 7576.0869 - val_mae: 54.0651\n",
            "Epoch 217/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5968.8813 - mae: 49.0840 - val_loss: 6715.2251 - val_mae: 51.3701\n",
            "Epoch 218/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5856.3794 - mae: 48.7295 - val_loss: 6981.6479 - val_mae: 52.2116\n",
            "Epoch 219/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6008.8838 - mae: 48.9929 - val_loss: 6620.6353 - val_mae: 50.6135\n",
            "Epoch 220/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5865.3813 - mae: 48.4840 - val_loss: 6757.3940 - val_mae: 51.3317\n",
            "Epoch 221/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5763.8154 - mae: 48.2488 - val_loss: 6868.4502 - val_mae: 51.8913\n",
            "Epoch 222/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6001.5830 - mae: 49.0103 - val_loss: 6788.5190 - val_mae: 51.3398\n",
            "Epoch 223/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 5704.6348 - mae: 47.9655 - val_loss: 6782.3970 - val_mae: 51.4359\n",
            "Epoch 224/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5826.1211 - mae: 48.1795 - val_loss: 7171.8135 - val_mae: 53.2882\n",
            "Epoch 225/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 6010.7690 - mae: 48.7141 - val_loss: 6716.1079 - val_mae: 50.8489\n",
            "Epoch 226/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5797.4062 - mae: 48.2154 - val_loss: 6898.0532 - val_mae: 52.0908\n",
            "Epoch 227/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5946.1367 - mae: 48.6349 - val_loss: 6751.0562 - val_mae: 51.4695\n",
            "Epoch 228/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5923.5034 - mae: 48.5541 - val_loss: 6940.3164 - val_mae: 52.2526\n",
            "Epoch 229/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5791.1963 - mae: 47.7963 - val_loss: 6767.0298 - val_mae: 51.3135\n",
            "Epoch 230/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5810.3389 - mae: 48.2387 - val_loss: 6773.7021 - val_mae: 51.5528\n",
            "Epoch 231/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5848.4722 - mae: 48.5261 - val_loss: 6696.0918 - val_mae: 51.1255\n",
            "Epoch 232/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5973.2227 - mae: 48.4690 - val_loss: 6732.4248 - val_mae: 51.0424\n",
            "Epoch 233/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5743.4570 - mae: 48.0710 - val_loss: 6963.4268 - val_mae: 51.9501\n",
            "Epoch 234/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5793.9507 - mae: 47.9240 - val_loss: 7433.0342 - val_mae: 54.5177\n",
            "Epoch 235/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5865.6538 - mae: 48.3026 - val_loss: 6787.5254 - val_mae: 51.3312\n",
            "Epoch 236/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5892.0518 - mae: 48.4161 - val_loss: 6665.7295 - val_mae: 50.9201\n",
            "Epoch 237/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5841.7329 - mae: 47.8847 - val_loss: 6729.6675 - val_mae: 51.2268\n",
            "Epoch 238/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5759.5312 - mae: 48.0374 - val_loss: 6914.2197 - val_mae: 51.9677\n",
            "Epoch 239/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5835.9263 - mae: 48.1211 - val_loss: 6876.4863 - val_mae: 51.5436\n",
            "Epoch 240/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5746.0547 - mae: 47.8693 - val_loss: 6625.5220 - val_mae: 50.6102\n",
            "Epoch 241/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5763.5264 - mae: 47.8281 - val_loss: 6634.6484 - val_mae: 50.6843\n",
            "Epoch 242/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5761.0913 - mae: 47.9013 - val_loss: 7087.3979 - val_mae: 52.2618\n",
            "Epoch 243/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5840.8955 - mae: 48.2638 - val_loss: 7163.6074 - val_mae: 52.9811\n",
            "Epoch 244/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5837.9438 - mae: 48.2923 - val_loss: 6644.8770 - val_mae: 51.0114\n",
            "Epoch 245/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5631.5669 - mae: 47.5769 - val_loss: 6818.4629 - val_mae: 51.5950\n",
            "Epoch 246/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5840.9590 - mae: 48.3496 - val_loss: 6761.3169 - val_mae: 51.4665\n",
            "Epoch 247/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5664.1323 - mae: 47.5325 - val_loss: 6721.2183 - val_mae: 50.9106\n",
            "Epoch 248/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5719.8726 - mae: 47.8132 - val_loss: 6606.5796 - val_mae: 50.6037\n",
            "Epoch 249/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 5687.0034 - mae: 47.6236 - val_loss: 7262.0771 - val_mae: 53.1477\n",
            "Epoch 250/250\n",
            "\u001b[1m1125/1125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 5763.0430 - mae: 47.8387 - val_loss: 6819.2437 - val_mae: 51.5896\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6953.0894 - mae: 51.4471\n",
            "Test MAE: 51.59\n",
            "\u001b[1m3515/3515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "✅ CSV export complete!\n"
          ]
        }
      ]
    }
  ]
}