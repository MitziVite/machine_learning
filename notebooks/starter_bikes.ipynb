{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_bikes.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MitziVite/machine_learning/blob/main/notebooks/starter_bikes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA0HPVmIBT4C"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "bikes = pd.read_csv('https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/bikes.csv')\n",
        "bikes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiU5QcPPxqQ"
      },
      "source": [
        "bikes[\"total_rentals\"] = bikes[\"casual\"] + bikes[\"registered\"]\n",
        "\n",
        "bikes[\"dteday\"] = pd.to_datetime(bikes[\"dteday\"])\n",
        "bikes[\"day\"] = bikes[\"dteday\"].dt.day\n",
        "bikes[\"month\"] = bikes[\"dteday\"].dt.month\n",
        "bikes[\"year\"] = bikes[\"dteday\"].dt.year\n",
        "\n",
        "features = [\n",
        "    \"hr\", \"temp_c\", \"feels_like_c\", \"hum\", \"windspeed\",\n",
        "    \"weathersit\", \"season\", \"holiday\", \"workingday\",\n",
        "    \"day\", \"month\", \"year\"\n",
        "]\n",
        "\n",
        "X = bikes[features]\n",
        "y = bikes[\"total_rentals\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLMN63FPyEQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnGBwGVZPyyh"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {mae:.2f}\")\n",
        "\n",
        "# Predictions\n",
        "bikes[\"predicted_total\"] = model.predict(scaler.transform(X))\n",
        "\n",
        "# Save only the first 384 predictions as 'total_rentals'\n",
        "bikes[\"predicted_total\"].head(384).to_csv(\"bike_predictions.csv\", index=False, header=['total_rentals'])\n",
        "print(\"✅ CSV export complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVSfaqgKPzE2"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1c19b4f"
      },
      "source": [
        "# Task\n",
        "Improve the model's performance in the notebook \"/content/module04_biking_grading.ipynb\" by iterating on the model architecture, hyperparameters, feature engineering, and regularization techniques, evaluating the results using the provided metrics (Within 5%, Within 10%, Within 20%, R^2, RMSE, MAE, MedAE) after each change, and summarizing the changes and results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603247c3"
      },
      "source": [
        "## Revisar la arquitectura del modelo\n",
        "\n",
        "### Subtask:\n",
        "Experimentar con un número diferente de capas densas y neuronas en cada capa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9960693"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the model architecture with a different number of dense layers and neurons, keeping the input shape and the output layer the same, and then train and evaluate the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a61bd342",
        "outputId": "793249b8-6b3b-432f-9708-5e04ddee94c4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f\"Test MAE: {mae:.2f}\")\n",
        "\n",
        "# Predictions\n",
        "bikes[\"predicted_total\"] = model.predict(scaler.transform(X))\n",
        "\n",
        "# Save only the first 384 predictions as 'total_rentals'\n",
        "bikes[\"predicted_total\"].head(384).to_csv(\"bike_predictions.csv\", index=False, header=['total_rentals'])\n",
        "print(\"✅ CSV export complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 97607.5703 - mae: 216.3812 - val_loss: 55965.7500 - val_mae: 161.7323\n",
            "Epoch 2/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 51061.4766 - mae: 152.2376 - val_loss: 39970.6016 - val_mae: 127.8822\n",
            "Epoch 3/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 37697.1328 - mae: 125.5851 - val_loss: 30557.0488 - val_mae: 114.4259\n",
            "Epoch 4/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 28406.2695 - mae: 108.2564 - val_loss: 22247.0840 - val_mae: 94.4678\n",
            "Epoch 5/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 21021.8828 - mae: 92.9941 - val_loss: 19584.2285 - val_mae: 89.4839\n",
            "Epoch 6/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 17121.4648 - mae: 83.3580 - val_loss: 14845.8818 - val_mae: 76.5877\n",
            "Epoch 7/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 14447.5713 - mae: 76.5932 - val_loss: 13144.9307 - val_mae: 72.5155\n",
            "Epoch 8/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 12915.7188 - mae: 72.1495 - val_loss: 12404.4600 - val_mae: 69.5621\n",
            "Epoch 9/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 11915.8525 - mae: 69.6141 - val_loss: 11330.4131 - val_mae: 67.4003\n",
            "Epoch 10/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11049.6475 - mae: 66.7380 - val_loss: 10317.1934 - val_mae: 64.3623\n",
            "Epoch 11/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 10456.4150 - mae: 64.5699 - val_loss: 9866.9502 - val_mae: 62.5344\n",
            "Epoch 12/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 9691.4727 - mae: 62.8000 - val_loss: 11648.1641 - val_mae: 68.8858\n",
            "Epoch 13/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 9568.0059 - mae: 62.0843 - val_loss: 9275.7607 - val_mae: 61.0143\n",
            "Epoch 14/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 9185.5723 - mae: 60.7533 - val_loss: 8819.3330 - val_mae: 59.7218\n",
            "Epoch 15/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 8882.8438 - mae: 59.8293 - val_loss: 8548.7598 - val_mae: 58.7541\n",
            "Epoch 16/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8550.1436 - mae: 58.6676 - val_loss: 8435.7393 - val_mae: 57.9162\n",
            "Epoch 17/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8506.5898 - mae: 58.3926 - val_loss: 8365.7793 - val_mae: 57.9166\n",
            "Epoch 18/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8161.6294 - mae: 57.4199 - val_loss: 8681.5771 - val_mae: 58.6099\n",
            "Epoch 19/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8161.9453 - mae: 57.0456 - val_loss: 8069.4233 - val_mae: 56.4868\n",
            "Epoch 20/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7930.4131 - mae: 56.4568 - val_loss: 8708.0635 - val_mae: 58.5829\n",
            "Epoch 21/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8027.0610 - mae: 56.5127 - val_loss: 7904.1353 - val_mae: 55.6584\n",
            "Epoch 22/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7997.0444 - mae: 56.1606 - val_loss: 7869.4961 - val_mae: 55.5876\n",
            "Epoch 23/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7834.4297 - mae: 55.9123 - val_loss: 8495.2568 - val_mae: 58.6711\n",
            "Epoch 24/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 7813.3281 - mae: 55.6547 - val_loss: 8211.5254 - val_mae: 56.7569\n",
            "Epoch 25/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 7798.9487 - mae: 55.3778 - val_loss: 8991.0088 - val_mae: 61.3775\n",
            "Epoch 26/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7804.6758 - mae: 55.6879 - val_loss: 7798.7676 - val_mae: 56.2940\n",
            "Epoch 27/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7407.1860 - mae: 54.4186 - val_loss: 7931.1440 - val_mae: 56.5670\n",
            "Epoch 28/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 7564.7026 - mae: 54.6174 - val_loss: 8326.3232 - val_mae: 57.1528\n",
            "Epoch 29/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 7387.1777 - mae: 54.0212 - val_loss: 7392.3442 - val_mae: 53.9379\n",
            "Epoch 30/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 7296.7861 - mae: 53.7264 - val_loss: 7810.6211 - val_mae: 56.0394\n",
            "Epoch 31/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7284.0293 - mae: 53.9526 - val_loss: 7973.7114 - val_mae: 56.1155\n",
            "Epoch 32/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7252.5127 - mae: 53.5304 - val_loss: 7720.0024 - val_mae: 55.2243\n",
            "Epoch 33/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7391.7583 - mae: 53.7987 - val_loss: 7366.7715 - val_mae: 54.0205\n",
            "Epoch 34/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7288.6050 - mae: 53.4608 - val_loss: 7738.0654 - val_mae: 55.4272\n",
            "Epoch 35/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7049.3198 - mae: 52.9654 - val_loss: 7436.5015 - val_mae: 54.1078\n",
            "Epoch 36/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7012.4434 - mae: 52.6486 - val_loss: 7396.2720 - val_mae: 54.6366\n",
            "Epoch 37/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 7172.1826 - mae: 52.9498 - val_loss: 7234.3984 - val_mae: 53.2114\n",
            "Epoch 38/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6956.1973 - mae: 52.4575 - val_loss: 7150.5479 - val_mae: 53.1222\n",
            "Epoch 39/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6941.6943 - mae: 52.4271 - val_loss: 7032.2729 - val_mae: 51.9752\n",
            "Epoch 40/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6803.1094 - mae: 51.9486 - val_loss: 7661.1396 - val_mae: 55.4050\n",
            "Epoch 41/50\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 6993.6064 - mae: 52.2054 - val_loss: 7070.1709 - val_mae: 52.1652\n",
            "Epoch 42/50\n",
            "\u001b[1m1900/2250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6830.0615 - mae: 52.1065"
          ]
        }
      ]
    }
  ]
}